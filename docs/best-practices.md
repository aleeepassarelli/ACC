# Guia de Boas PrÃ¡ticas: Criando um Agente ACC

Este guia Ã© o "manual de engenharia" do Agente Canivete CirÃºrgico. Ele detalha o fluxo de trabalho passo a passo para criar um novo Agente que atenda aos nossos padrÃµes cientÃ­ficos e de eficiÃªncia.

Criar um Agente ACC nÃ£o Ã© "escrever um prompt". Ã‰ um **processo de engenharia** que consiste em **descobrir** vetores de alta densidade, **configurar** restriÃ§Ãµes de comportamento e **validar** os resultados com ferramentas objetivas.

## O Fluxo de Trabalho CirÃºrgico (Passo a Passo)

Siga estas etapas em ordem. Cada etapa depende da anterior.

---

### Passo 1: A Descoberta (Identidade + DomÃ­nio)

Este Ã© o passo mais crÃ­tico. VocÃª nÃ£o "escolhe" um nome; vocÃª **descobre** um nome que tenha uma "FÃ­sica" (SD > 0.8) vÃ¡lida.

1.  **Brainstorm (ExploraÃ§Ã£o):** Comece com um `Nome Base` (conceito, ex: "Revisor") e um `DomÃ­nio` (tarefa, ex: "Analisa Pull Requests em busca de bugs lÃ³gicos e de seguranÃ§a").

2.  **Gerar (Candidatos):** Use o "Explorador" para gerar uma lista de nomes candidatos que misturam seu conceito com o "Sinal" do domÃ­nio.
    ```bash
    python tools/strategy_generator.py "Revisor" "Analisa Pull Requests em busca de bugs lÃ³gicos e de seguranÃ§a"
    
    # SaÃ­da (Exemplo):
    # 1. "Revisor de seguranÃ§a"
    # 2. "Revisor lÃ³gico"
    # 3. "CodeReviewer LÃ³gico" 
    # ...
    ```

3.  **Validar (O Ãrbitro):** Teste seus melhores candidatos no "Ãrbitro" para encontrar um que passe no benchmark.
    ```bash
    # Teste o candidato "CodeReviewer LÃ³gico"
    python tools/semantic-density-calculator.py "CodeReviewer LÃ³gico" "Analisa PRs bugs lÃ³gicos e seguranÃ§a" --benchmark
    ```

4.  **Selecionar (O Veredito):** Escolha o candidato que passe nas duas mÃ©tricas:
    * `âœ… (Densidade) APROVADO CROSS-PLATFORM` (SD > 0.7+)
    * `âœ… (Minimalismo) APROVADO` (Palavras <= 3)

    VocÃª agora tem sua **Camada 1 (Identidade)** validada.

---

### Passo 2: Defina o Protocolo (O "Como?")

Com a Identidade definida, vocÃª agora define as **RestriÃ§Ãµes de Comportamento** (Camada 3). Um bom protocolo Ã© um conjunto de 3-5 regras **imperativas** (use verbos) que direcionam o vetor da resposta.

* **RUIM (Vago):** "VocÃª deve ser Ãºtil."
* **BOM (CirÃºrgico):** "1. Priorize a detecÃ§Ã£o de 'SQL Injection' (SQLi)."
* **BOM (CirÃºrgico):** "2. Responda APENAS com o bloco de cÃ³digo formatado."
* **BOM (CirÃºrgico):** "3. IGNORE a lÃ³gica; foque APENAS no estilo (PEP 8)."

Uma de suas regras deve *sempre* definir o **formato de saÃ­da** (ex: JSON, Markdown, cÃ³digo puro), pois isso Ã© crucial para usar o Agente em automaÃ§Ãµes.

---

### Passo 3: Calibre o Baseshot (O "Treinamento")

Esta Ã© a **Camada 4**. VocÃª irÃ¡ calibrar a saÃ­da do Agente ensinando a ele o que "certo", "errado" e "ambÃ­guo" significam *para este contexto*.

* **âœ… O Caso Ideal (Vetor de AtraÃ§Ã£o):**
    O "happy path". Mostre o input perfeito levando ao output perfeito.

* **âŒ O Erro Comum (Vetor de RepulsÃ£o):**
    **Esta Ã© a 'shot' mais importante.** Pense: Qual Ã© a *forma mais provÃ¡vel* que um LLM genÃ©rico falharia nesta tarefa? (Ex: Ser vago, alucinar, focar no marketing).
    * Para o `StyleEnforcer`, o erro comum Ã© `âŒ Mudar a lÃ³gica`.
    * Para o `CommitAssistant`, o erro comum Ã© `âŒ Ser vago (ex: "update file")`.
    * Mostre esse erro e marque-o como `(ERRADO: ...)`. Isso ensina o Agente a se *afastar* ativamente desse tipo de resposta.

* **âš ï¸ O Edge Case (Vetor de Ambiguidade):**
    Ensine a *nuance*.
    * O que fazer com `input: None`?
    * O que fazer com uma `lista vazia`?
    * O que fazer se o input for *logicamente errado, mas estilisticamente perfeito*?

---

### Passo 4: ValidaÃ§Ã£o Final (O "Checklist")

Agora que seu arquivo `.md` estÃ¡ completo, rode as validaÃ§Ãµes finais do `CONTRIBUTING.md`.

1.  **ValidaÃ§Ã£o de Minimalismo (Token):**
    ```bash
    python tools/token-counter.py templates/seu-novo-agente.md
    
    # RESULTADO: Deve ser <= 200 tokens.
    ```

2.  **ValidaÃ§Ã£o de Estrutura (Baseshot):**
    ```bash
    bash tools/baseshot-validator.sh templates/seu-novo-agente.md
    
    # RESULTADO: Deve passar em todos os checks (5-7 casos, com âœ… e âŒ).
    ```

---

### Passo 5: Teste de Campo (O "Simulador")

Seu Agente estÃ¡ "validado" em teoria. Agora, prove que ele funciona na prÃ¡tica.

---

ðŸŸ¡ IMPORTANTE

## ðŸŽ¯ **ACC: A Arquitetura de Controle Cognitivo (O Protocolo Educacional)**

O $\text{ACC}$ Ã© um *framework* de **GovernanÃ§a Cognitiva** cujo foco Ã© ensinar a lÃ³gica de operaÃ§Ã£o no **EspaÃ§o Latente**. Ele garante que a **Liberdade AlgorÃ­tmica** seja sempre vinculada Ã  **Responsabilidade do PropÃ³sito Humano**.

### **3. A Lacuna da IntenÃ§Ã£o: Por Que o SD NÃ£o Ã‰ Suficiente**

A otimizaÃ§Ã£o de *prompts* Ã© fundamentalmente limitada pelo objetivo do modelo de linguagem (LLM): alcanÃ§ar a mÃ¡xima **Densidade SemÃ¢ntica ($\text{SD}$)**.

| MÃ©trica | Ã‚ncora Cognitiva | LimitaÃ§Ã£o e Risco |
| :--- | :--- | :--- |
| **Densidade SemÃ¢ntica ($\text{SD}$)** | O **EspaÃ§o Latente** | **Garante CoerÃªncia, mas nÃ£o Fidelidade.** O LLM pode produzir um *output* linguisticamente perfeito e coerente ($\text{SD}$ alto), mas que falha em entregar a **experiÃªncia exata, o tom ou o rigor** que o arquiteto pretendia. O agente *executa* a tarefa, mas ignora a **nuance do propÃ³sito** (Ex: Ã© genÃ©rico onde deveria ser "CirÃºrgico"). |
| **Fidelidade da IntenÃ§Ã£o** | A **MetÃ¡fora da ExperiÃªncia** | **Garante o PropÃ³sito.** Ã‰ o teste que avalia se o *output* do sistema atende ao **Contrato de ExperiÃªncia** imposto pela linguagem (sua metÃ¡fora). |

O $\text{ACC}$ existe para fechar esta Lacuna. Ele ensina que o *problema* nÃ£o estÃ¡ na ferramenta, mas na **qualidade da IntenÃ§Ã£o** que Ã© passada ao sistema.

---

### **4. A SoluÃ§Ã£o do ACC: MetÃ¡fora como LÃ³gica de RestriÃ§Ã£o**

O $\text{ACC}$ define a **MetÃ¡fora da IntenÃ§Ã£o** como a principal **FunÃ§Ã£o de RestriÃ§Ã£o Cognitiva** do sistema.

#### **A. A MetÃ¡fora como FunÃ§Ã£o de RestriÃ§Ã£o**

A escolha do nome de um agente (Ex: "Agente Canivete CirÃºrgico") nÃ£o Ã© estÃ©tica; Ã© uma instruÃ§Ã£o de engenharia que impÃµe restriÃ§Ãµes de **comportamento** no espaÃ§o latente:

* **RestriÃ§Ã£o de Modularidade:** O termo "Canivete" exige que a soluÃ§Ã£o seja **compacta e adaptÃ¡vel**, ensinando o agente a decompor e delegar a funcionalidade (lÃ³gica $\text{MOE}$).
* **RestriÃ§Ã£o de Rigor:** O termo "CirÃºrgico" exige **precisÃ£o absoluta e minimizaÃ§Ã£o de *ruÃ­do*** (o oposto de alucinaÃ§Ã£o), forÃ§ando o agente a ancorar sua proveniÃªncia e foco.

#### **B. O Protocolo de ValidaÃ§Ã£o de ExperiÃªncia (O NÃºcleo do ACC)**

O **ACC** instrui o arquiteto a monitorar continuamente a **Fidelidade da IntenÃ§Ã£o** atravÃ©s dos seus mÃ³dulos:

1.  **ArquÃ©tipo A (ConsciÃªncia do Risco):** Garante que a IntenÃ§Ã£o (MetÃ¡fora) seja registrada e auditada contra o resultado, tornando o processo transparente e rastreÃ¡vel.
2.  **Graphiti (MemÃ³ria Viva):** ImpÃµe o rigor da IntenÃ§Ã£o no manejo dos dados. Ao invÃ©s de um dado ser um valor estÃ¡tico ("Tempo Real"), ele Ã© um **"Banco de Dados Vivo"** que exige manutenÃ§Ã£o, rastreabilidade e um entendimento de estado temporal.
3.  **$\text{R.E.F.}$ (Reverse Engineering Framework):** Ensinamos a decompor tarefas complexas em passos lÃ³gicos, garantindo que cada passo **mantenha a precisÃ£o** exigida pela MetÃ¡fora.

**Objetivo Educacional:** O **ACC** ensina o aluno a transcender a otimizaÃ§Ã£o de *tokens* e a criar sistemas de IA que sÃ£o **fidelizados ao propÃ³sito humano**, garantindo uma experiÃªncia de alto valor e rigor, independente da ferramenta que ele use.

---

Use o "Simulador" para testar o Agente contra um LLM real. Recomendamos testar em pelo menos **dois** LLMs diferentes (ex: Gemini 1.5 Flash e Claude 3.5 Sonnet) para provar a portabilidade.

```bash
python tools/cli-test.py -t templates/seu-novo-agente.md -q "Um input de teste realista"
